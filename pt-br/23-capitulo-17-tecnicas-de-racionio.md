# Capítulo 17: Técnicas de Raciocínio

Este capítulo aprofunda metodologias de raciocínio avançadas para agentes inteligentes, focando em inferências lógicas multi-passo e resolução de problemas. Estas técnicas vão além de operações sequenciais simples, tornando o raciocínio interno do agente explícito. Isto permite que agentes dividam problemas, considerem passos intermediários e alcancem conclusões mais robustas e precisas. Um princípio central entre estes métodos avançados é a alocação de recursos computacionais aumentados durante a inferência. Isto significa conceder ao agente, ou ao LLM subjacente, mais tempo de processamento ou passos para processar uma consulta e gerar uma resposta. Ao invés de uma passada rápida e única, o agente pode se envolver em refinamento iterativo, explorar múltiplos caminhos de solução ou utilizar ferramentas externas. Este tempo de processamento estendido durante a inferência frequentemente aprimora significativamente precisão, coerência e robustez, especialmente para problemas complexos requerendo análise e deliberação mais profundas.

# Aplicações Práticas e Casos de Uso

Aplicações práticas incluem:

* **Resposta a Questões Complexas:** Facilitando a resolução de consultas multi-hop, que necessitam a integração de dados de fontes diversas e a execução de deduções lógicas, potencialmente envolvendo o exame de múltiplos caminhos de raciocínio, e se beneficiando de tempo de inferência estendido para sintetizar informação.  
* **Resolução de Problemas Matemáticos:** Permitindo a divisão de problemas matemáticos em componentes menores e solucionáveis, ilustrando o processo passo-a-passo, e empregando execução de código para computações precisas, onde inferência prolongada permite geração e validação de código mais intrincadas.  
* **Depuração e Geração de Código:** Apoiando a explicação de um agente de sua racionalidade para gerar ou corrigir código, identificando problemas potenciais sequencialmente, e refinando iterativamente o código baseado em resultados de teste (Auto-Correção), aproveitando tempo de inferência estendido para ciclos de depuração minuciosos.  
* **Planejamento Estratégico:** Auxiliando no desenvolvimento de planos abrangentes através de raciocínio através de várias opções, consequências e pré-condições, e ajustando planos baseados em feedback em tempo real (ReAct), onde deliberação estendida pode levar a planos mais efetivos e confiáveis.  
* **Diagnóstico Médico:** Auxiliando um agente na avaliação sistemática de sintomas, resultados de teste e históricos de pacientes para chegar a um diagnóstico, articulando seu raciocínio em cada fase, e potencialmente utilizando instrumentos externos para recuperação de dados (ReAct). Tempo de inferência aumentado permite um diagnóstico diferencial mais abrangente.  
* **Análise Legal:** Apoiando a análise de documentos legais e precedentes para formular argumentos ou fornecer orientação, detalhando os passos lógicos tomados, e garantindo consistência lógica através de auto-correção. Tempo de inferência aumentado permite pesquisa legal e construção de argumentos mais aprofundadas.

# Técnicas de raciocínio

Para começar, vamos aprofundar as técnicas de raciocínio centrais usadas para aprimorar as habilidades de resolução de problemas de modelos de IA.

**Chain-of-Thought (CoT)** prompting aprimora significativamente as habilidades de raciocínio complexo de LLMs imitando um processo de pensamento passo-a-passo (veja Fig. 1). Ao invés de fornecer uma resposta direta, prompts CoT guiam o modelo a gerar uma sequência de passos de raciocínio intermediários. Esta divisão explícita permite que LLMs lidem com problemas complexos decompondo-os em sub-problemas menores e mais gerenciáveis. Esta técnica melhora marcadamente o desempenho do modelo em tarefas requerendo raciocínio multi-passo, como aritmética, raciocínio de senso comum e manipulação simbólica. Uma vantagem primária do CoT é sua capacidade de transformar um problema difícil de passo único em uma série de passos mais simples, aumentando assim a transparência do processo de raciocínio do LLM. Esta abordagem não apenas aumenta a precisão mas também oferece insights valiosos sobre a tomada de decisão do modelo, auxiliando em depuração e compreensão. CoT pode ser implementado usando várias estratégias, incluindo oferecer exemplos few-shot que demonstram raciocínio passo-a-passo ou simplesmente instruir o modelo a "pensar passo a passo." Sua efetividade deriva de sua capacidade de guiar o processamento interno do modelo em direção a uma progressão mais deliberada e lógica. Como resultado, Chain-of-Thought tornou-se uma técnica fundamental para permitir capacidades de raciocínio avançadas em LLMs contemporâneos. Esta transparência aprimorada e divisão de problemas complexos em sub-problemas gerenciáveis é particularmente importante para agentes autônomos, pois permite que executem ações mais confiáveis e auditáveis em ambientes complexos.  
![][image1]  
Fig. 1: Prompt CoT junto com a resposta detalhada e passo-a-passo gerada pelo agente.

Vamos ver um exemplo. Ele começa com um conjunto de instruções que dizem à IA como pensar, definindo sua persona e um processo claro de cinco passos a seguir. Este é o prompt que inicia o pensamento estruturado.

Seguindo isso, o exemplo mostra o processo CoT em ação. A seção rotulada "Processo de Pensamento do Agente" é o monólogo interno onde o modelo executa os passos instruídos. Esta é a literal "cadeia de pensamento." Finalmente, a "Resposta Final do Agente" é a saída polida e abrangente gerada como resultado daquele processo de raciocínio cuidadoso e passo-a-passo

| `Você é um Agente de Recuperação de Informação. Seu objetivo é responder à pergunta do usuário de forma abrangente e precisa pensando passo-a-passo. Aqui está o processo que você deve seguir: 1.  **Analisar a Consulta:** Entender o assunto central e requisitos específicos da pergunta do usuário. Identificar entidades chave, palavras-chave e o tipo de informação sendo procurada. 2.  **Formular Consultas de Busca (para Base de Conhecimento):** Baseado em sua análise, gerar uma lista de consultas de busca precisas que você usaria para recuperar informação relevante de uma base de conhecimento ou ferramentas externas. 3.  **Simular Recuperação de Informação (Auto-Correção/Raciocínio):** Para cada consulta de busca, considerar mentalmente que tipo de informação você espera encontrar. Se você fosse recuperar o conteúdo, quais seriam os snippets mais relevantes? Pense sobre ambiguidades potenciais ou peças ausentes. 4.  **Sintetizar Informação:** Baseado na recuperação simulada e seu entendimento da consulta original do usuário, sintetizar a informação reunida em uma resposta coerente e completa. Garantir que todos os aspectos da consulta sejam abordados. 5.  **Revisar e Refinar:** Antes de finalizar, avaliar criticamente sua resposta. É precisa? É abrangente? É fácil de entender? É concisa? Se não, identificar o que precisa ser melhorado e como. **Consulta do Usuário:** "Explique as principais diferenças entre computadores clássicos e computadores quânticos, e descreva brevemente uma aplicação potencial da computação quântica." **Processo de Pensamento do Agente (Saída CoT Interna - encorajada pelo prompt):** **Pensamento 1 (Analisar Consulta):** O usuário quer duas coisas: 1.  Principais diferenças entre computadores clássicos e quânticos. 2.  Uma aplicação potencial da computação quântica. Palavras-chave: computadores clássicos, computadores quânticos, diferenças, aplicação potencial. **Pensamento 2 (Formular Consultas de Busca):** - "diferenças clássicos vs quânticos" - "como computadores quânticos funcionam" - "como computadores clássicos funcionam" - "aplicações da computação quântica" **Pensamento 3 (Simular Recuperação de Informação & Identificar Conceitos Chave):** - De "diferenças": Esperar conceitos como bits vs. qubits, superposição, entrelaçamento, natureza probabilística, poder computacional para problemas específicos. - De "como funcionam": Clássicos usam transistores/binário. Quânticos usam mecânica quântica. - De "aplicações": Esperar descoberta de drogas, ciência de materiais, criptografia, otimização. **Pensamento 4 (Sintetizar Informação):** Computadores clássicos usam bits (0 ou 1), processando informação sequencialmente. Computadores quânticos usam qubits, que podem ser 0, 1, ou ambos simultaneamente (superposição), e podem ser entrelaçados, permitindo abordagens computacionais vastamente diferentes. Isto permite que resolvam certos problemas (como fatorar números grandes ou simular moléculas complexas) muito mais eficientemente que computadores clássicos. Uma aplicação potencial é na descoberta de drogas, onde computadores quânticos poderiam simular interações moleculares com precisão sem precedentes, acelerando o desenvolvimento de novos medicamentos. **Pensamento 5 (Revisar e Refinar):** - Diferenças estão cobertas (bits vs qubits, superposição, entrelaçamento, processamento). - Aplicação é dada (descoberta de drogas). - É breve? Sim. - É claro? Sim. - Parece bom. **Resposta Final do Agente (Saída para Usuário):** Computadores clássicos processam informação usando bits, que podem ser 0 ou 1 a qualquer momento dado, realizando operações sequencialmente. Em contraste, computadores quânticos utilizam qubits, que podem existir em múltiplos estados simultaneamente através de superposição e podem ser ligados através de entrelaçamento, permitindo computações exponencialmente mais complexas. Esta diferença fundamental permite que máquinas quânticas lidem com certos problemas, como simular estruturas moleculares ou quebrar criptografia complexa, que são intratáveis mesmo para os supercomputadores clássicos mais poderosos. Uma aplicação significativa potencial da computação quântica está na descoberta de drogas, onde sua capacidade de modelar precisamente o comportamento molecular poderia revolucionar o desenvolvimento de novos produtos farmacêuticos.` |
| :---- |

**Tree-of-Thought (ToT)** é uma técnica de raciocínio que constrói sobre Chain-of-Thought (CoT). Ela permite que grandes modelos de linguagem explorem múltiplos caminhos de raciocínio ramificando em diferentes passos intermediários, formando uma estrutura de árvore (veja Fig. 2) Esta abordagem suporta resolução de problemas complexos permitindo backtracking, auto-correção e exploração de soluções alternativas. Manter uma árvore de possibilidades permite que o modelo avalie várias trajetórias de raciocínio antes de finalizar uma resposta. Este processo iterativo aprimora a capacidade do modelo de lidar com tarefas desafiadoras que requerem planejamento estratégico e tomada de decisão.  
![][image2]  
Fig.2: Exemplo de Árvore de Pensamentos

**Auto-correção**, também conhecida como auto-refinamento, é um aspecto crucial do processo de raciocínio de um agente, particularmente dentro do prompting Chain-of-Thought. Ela envolve a avaliação interna do agente de seu conteúdo gerado e processos de pensamento intermediários. Esta revisão crítica permite que o agente identifique ambiguidades, lacunas de informação ou imprecisões em seu entendimento ou soluções. Este ciclo iterativo de revisar e refinar permite que o agente ajuste sua abordagem, melhore a qualidade da resposta e garanta precisão e minuciosidade antes de entregar uma saída final. Esta crítica interna aprimora a capacidade do agente de produzir resultados confiáveis e de alta qualidade, como demonstrado em exemplos dentro do Capítulo 4 dedicado.

Este exemplo demonstra um processo sistemático de auto-correção, crucial para refinar conteúdo gerado por IA. Envolve um loop iterativo de rascunho, revisão contra requisitos originais e implementação de melhorias específicas. A ilustração começa delineando a função da IA como um "Agente de Auto-Correção" com um fluxo de trabalho analítico e de revisão de cinco passos definido. Seguindo isso, um "Rascunho Inicial" subpar de um post de mídia social é apresentado. O "Processo de Pensamento do Agente de Auto-Correção" forma o núcleo da demonstração. Aqui, o Agente avalia criticamente o rascunho de acordo com suas instruções, identificando fraquezas como baixo engajamento e uma chamada para ação vaga. Ele então sugere melhorias concretas, incluindo o uso de verbos mais impactantes e emojis. O processo conclui com o "Conteúdo Final Revisado," uma versão polida e notavelmente melhorada que integra os ajustes auto-identificados.

| `Você é um Agente de Auto-Correção altamente crítico e orientado a detalhes. Sua tarefa é revisar uma peça de conteúdo previamente gerada contra seus requisitos originais e identificar áreas para melhoria. Seu objetivo é refinar o conteúdo para ser mais preciso, abrangente, envolvente e alinhado com o prompt. Aqui está o processo que você deve seguir para auto-correção: 1.  **Entender Requisitos Originais:** Revisar o prompt/requisitos iniciais que levaram à criação do conteúdo. Qual era a *intenção original*? Quais eram as principais restrições ou objetivos? 2.  **Analisar Conteúdo Atual:** Ler o conteúdo fornecido cuidadosamente. 3.  **Identificar Discrepâncias/Fraquezas:** Comparar o conteúdo atual contra os requisitos originais. Procurar por:    * **Problemas de Precisão:** Há erros factuais ou declarações enganosas?    * **Lacunas de Completude:** Aborda completamente todos os aspectos do prompt original? Há algo faltando?    * **Clareza & Coerência:** A linguagem é clara, concisa e fácil de entender? Flui logicamente?    * **Tom & Estilo:** Combina com o tom e estilo desejados (ex., profissional, envolvente, conciso)?    * **Engajamento:** É cativante? Mantém a atenção do leitor?    * **Redundância/Verbosidade:** Algumas partes podem ser condensadas ou removidas sem perder significado? 4.  **Propor Melhorias Específicas:** Para cada fraqueza identificada, sugerir mudanças concretas e acionáveis. Não apenas declarar o problema; propor uma solução. 5.  **Gerar Conteúdo Revisado:** Baseado em suas melhorias propostas, reescrever o conteúdo original para incorporar todas as mudanças necessárias. Garantir que o conteúdo revisado seja polido e pronto para uso final. **Prompt/Requisitos Originais:** "Escreva um post curto e envolvente de mídia social (máx 150 caracteres) anunciando uma nova linha de produtos eco-friendly: 'GreenTech Gadgets'." **Rascunho Inicial (Conteúdo a ser corrigido):** "Temos novos produtos. Eles são verdes e tecnológicos. Compre GreenTech Gadgets agora!" **Processo de Pensamento do Agente de Auto-Correção (Saída CoT Interna - encorajada pelo prompt):** **Pensamento 1 (Entender Requisitos Originais):** - Post curto e envolvente de mídia social. - Máx 150 caracteres. - Anunciar "GreenTech Gadgets" - uma nova linha de produtos eco-friendly. **Pensamento 2 (Analisar Conteúdo Atual):** "Temos novos produtos. Eles são verdes e tecnológicos. Compre GreenTech Gadgets agora!" (64 caracteres) **Pensamento 3 (Identificar Discrepâncias/Fraquezas):** - **Envolvente:** Não muito envolvente. Soa genérico. - **Eco-friendly:** Implícito por "verde," mas não destacado explicitamente como benefício. - **Chamada para Ação:** "Compre agora!" está ok, mas poderia ser mais convincente. - **Concisão:** É curto, mas poderia usar verbos/frases mais fortes. - **Impacto:** Falta emoção para um lançamento de novo produto. **Pensamento 4 (Propor Melhorias Específicas):** - Tornar mais dinâmico e emocionante. - Enfatizar "eco-friendly" e "inovação." - Usar verbos mais fortes e voz mais ativa. - Adicionar uma chamada para ação clara e envolvente. - Garantir que permaneça sob 150 caracteres. **Pensamento 5 (Gerar Conteúdo Revisado):** Original: "Temos novos produtos. Eles são verdes e tecnológicos. Compre GreenTech Gadgets agora!" Ideia revisada 1: "🌱 Descubra GreenTech Gadgets! Nossa nova linha eco-friendly combina inovação com sustentabilidade. Seja verde, seja inteligente! Compre agora! #EcoFriendly #GreenTech" (148 caracteres) Esta revisão aborda diretamente eco-friendliness, usa emojis para engajamento, adiciona uma chamada para ação mais forte e inclui hashtags relevantes enquanto permanece dentro do limite de caracteres. **Conteúdo Final Revisado do Agente de Auto-Correção (Saída para Usuário):** 🌱 Descubra GreenTech Gadgets! Nossa nova linha eco-friendly combina inovação com sustentabilidade. Seja verde, seja inteligente! Compre agora! #EcoFriendly #GreenTech` |
| :---- |

Fundamentalmente, esta técnica integra uma medida de controle de qualidade diretamente na geração de conteúdo do Agente, produzindo resultados mais refinados, precisos e superiores que atendem mais efetivamente demandas intrincadas do usuário.

**Modelos de Linguagem Ajudados por Programa (PALMs)** integram LLMs com capacidades de raciocínio simbólico. Esta integração permite que o LLM gere e execute código, como Python, como parte de seu processo de resolução de problemas. PALMs transferem cálculos complexos, operações lógicas e manipulação de dados para um ambiente de programação determinístico. Esta abordagem utiliza os pontos fortes da programação tradicional para tarefas onde LLMs podem exibir limitações em precisão ou consistência. Quando confrontado com desafios simbólicos, o modelo pode produzir código, executá-lo e converter os resultados em linguagem natural. Esta metodologia híbrida combina as habilidades de entendimento e geração do LLM com computação precisa, permitindo que o modelo aborde uma gama mais ampla de problemas complexos com potencialmente maior confiabilidade e precisão. Isto é importante para agentes pois permite que executem ações mais precisas e confiáveis aproveitando computação precisa junto com suas habilidades de entendimento e geração. Um exemplo é o uso de ferramentas externas dentro do ADK do Google para gerar código.

| `from google.adk.tools import agent_tool from google.adk.agents import Agent from google.adk.tools import google_search from google.adk.code_executors import BuiltInCodeExecutor search_agent = Agent(    model='gemini-2.0-flash',    name='SearchAgent',    instruction="""    Você é um especialista em Google Search    """,    tools=[google_search], ) coding_agent = Agent(    model='gemini-2.0-flash',    name='CodeAgent',    instruction="""    Você é um especialista em Execução de Código    """,    code_executor=[BuiltInCodeExecutor], ) root_agent = Agent(    name="RootAgent",    model="gemini-2.0-flash",    description="Agente Raiz",    tools=[agent_tool.AgentTool(agent=search_agent), agent_tool.AgentTool(agent=coding_agent)], )` |
| :---- |

**Aprendizado por Reforço com Recompensas Verificáveis (RLVR):** Embora efetivo, o prompting Chain-of-Thought (CoT) padrão usado por muitos LLMs é uma abordagem um tanto básica ao raciocínio. Ele gera uma única linha de pensamento predeterminada sem se adaptar à complexidade do problema. Para superar estas limitações, uma nova classe de "modelos de raciocínio" especializados foi desenvolvida. Estes modelos operam diferentemente dedicando uma quantidade variável de tempo de "pensamento" antes de fornecer uma resposta. Este processo de "pensamento" produz uma Chain-of-Thought mais extensa e dinâmica que pode ter milhares de tokens de comprimento. Este raciocínio estendido permite comportamentos mais complexos como auto-correção e backtracking, com o modelo dedicando mais esforço a problemas mais difíceis. A inovação chave permitindo estes modelos é uma estratégia de treinamento chamada Aprendizado por Reforço de Recompensas Verificáveis (RLVR). Treinando o modelo em problemas com respostas corretas conhecidas (como matemática ou código), ele aprende através de tentativa e erro a gerar raciocínio efetivo de forma longa. Isto permite que o modelo evolua suas habilidades de resolução de problemas sem supervisão humana direta. Em última análise, estes modelos de raciocínio não apenas produzem uma resposta; eles geram uma "trajetória de raciocínio" que demonstra habilidades avançadas como planejamento, monitoramento e avaliação. Esta capacidade aprimorada de raciocinar e estrategizar é fundamental para o desenvolvimento de agentes de IA autônomos, que podem dividir e resolver tarefas complexas com intervenção humana mínima.

**ReAct** (Raciocínio e Ação, veja Fig. 3, onde KB significa Base de Conhecimento) é um paradigma que integra prompting Chain-of-Thought (CoT) com a capacidade de um agente de interagir com ambientes externos através de ferramentas. Ao contrário de modelos generativos que produzem uma resposta final, um agente ReAct raciocina sobre quais ações tomar. Esta fase de raciocínio envolve um processo de planejamento interno, similar ao CoT, onde o agente determina seus próximos passos, considera ferramentas disponíveis e antecipa resultados. Seguindo isso, o agente age executando uma ferramenta ou chamada de função, como consultar um banco de dados, realizar um cálculo ou interagir com uma API.

![][image3]

Fig.3: Raciocínio e Ação

ReAct opera de forma intercalada: o agente executa uma ação, observa o resultado e incorpora esta observação no raciocínio subsequente. Este loop iterativo de "Pensamento, Ação, Observação, Pensamento..." permite que o agente adapte dinamicamente seu plano, corrija erros e atinja objetivos requerendo múltiplas interações com o ambiente. Isto fornece uma abordagem de resolução de problemas mais robusta e flexível comparada ao CoT linear, pois o agente responde ao feedback em tempo real. Ao combinar entendimento e geração de modelo de linguagem com a capacidade de usar ferramentas, ReAct permite que agentes executem tarefas complexas requerendo tanto raciocínio quanto execução prática. Esta abordagem é crucial para agentes pois permite que não apenas raciocinem mas também executem praticamente passos e interajam com ambientes dinâmicos.

**CoD** (Chain of Debates) é um framework formal de IA proposto pela Microsoft onde múltiplos modelos diversos colaboram e argumentam para resolver um problema, movendo além da "cadeia de pensamento" de uma única IA. Este sistema opera como uma reunião de conselho de IA, onde diferentes modelos apresentam ideias iniciais, criticam o raciocínio uns dos outros e trocam contra-argumentos. O objetivo primário é aprimorar precisão, reduzir viés e melhorar a qualidade geral da resposta final aproveitando inteligência coletiva. Funcionando como uma versão IA de revisão por pares, este método cria um registro transparente e confiável do processo de raciocínio. Em última análise, representa uma mudança de um Agente solitário fornecendo uma resposta para uma equipe colaborativa de Agentes trabalhando juntos para encontrar uma solução mais robusta e validada.

**GoD** (Graph of Debates) é um framework Agêntico avançado que reimagina discussão como uma rede dinâmica e não-linear ao invés de uma cadeia simples. Neste modelo, argumentos são nós individuais conectados por arestas que significam relacionamentos como 'apoia' ou 'refuta,' refletindo a natureza multi-threaded do debate real. Esta estrutura permite que novas linhas de investigação se ramifiquem dinamicamente, evoluam independentemente e até se fundam ao longo do tempo. Uma conclusão é alcançada não no final de uma sequência, mas identificando o cluster mais robusto e bem apoiado de argumentos dentro de todo o grafo. Neste contexto, "bem apoiado" refere-se a conhecimento que é firmemente estabelecido e verificável. Isto pode incluir informação considerada como verdade fundamental, que significa que é inerentemente correta e amplamente aceita como fato. Adicionalmente, abrange evidência factual obtida através de fundamentação de busca, onde informação é validada contra fontes externas e dados do mundo real. Finalmente, também se refere a um consenso alcançado por múltiplos modelos durante um debate, indicando um alto grau de acordo e confiança na informação apresentada. Esta abordagem abrangente garante uma base mais robusta e confiável para a informação sendo discutida. Esta abordagem fornece um modelo mais holístico e realista para raciocínio colaborativo de IA complexo.

**MASS (tópico avançado opcional):** Uma análise aprofundada do design de sistemas multi-agente revela que sua efetividade é criticamente dependente tanto da qualidade dos prompts usados para programar agentes individuais quanto da topologia que dita suas interações. A complexidade de projetar estes sistemas é significativa, pois envolve um espaço de busca vasto e intrincado. Para abordar este desafio, um framework novo chamado Multi-Agent System Search (MASS) foi desenvolvido para automatizar e otimizar o design de MAS.

MASS emprega uma estratégia de otimização multi-estágio que navega sistematicamente o espaço de design complexo intercalando otimização de prompt e topologia (veja Fig. 4)

#### **1. Otimização de Prompt Nível de Bloco:** O processo começa com uma otimização local de prompts para tipos de agentes individuais, ou "blocos," para garantir que cada componente execute seu papel efetivamente antes de ser integrado em um sistema maior. Este passo inicial é crucial pois garante que a otimização de topologia subsequente construa sobre agentes bem performantes, ao invés de sofrer do impacto composto de agentes mal configurados. Por exemplo, ao otimizar para o dataset HotpotQA, o prompt para um agente "Debator" é criativamente enquadrado para instruí-lo a agir como um "verificador de fatos especialista para uma publicação major." Sua tarefa otimizada é revisar meticulosamente respostas propostas de outros agentes, fazer referência cruzada com passagens de contexto fornecidas e identificar qualquer inconsistência ou declaração não apoiada. Este prompt de role-playing especializado, descoberto durante otimização nível de bloco, visa tornar o agente debator altamente efetivo em sintetizar informação antes mesmo de ser colocado em um fluxo de trabalho maior.

#### **2. Otimização de Topologia de Fluxo de Trabalho:** Seguindo otimização local, MASS otimiza a topologia de fluxo de trabalho selecionando e organizando diferentes interações de agentes de um espaço de design customizável. Para tornar esta busca eficiente, MASS emprega um método ponderado por influência. Este método calcula a "influência incremental" de cada topologia medindo seu ganho de desempenho relativo a um agente baseline e usa estas pontuações para guiar a busca em direção a combinações mais promissoras. Por exemplo, ao otimizar para a tarefa de codificação MBPP, a busca de topologia descobre que um fluxo de trabalho híbrido específico é mais efetivo. A topologia melhor encontrada não é uma estrutura simples mas uma combinação de um processo de refinamento iterativo com uso de ferramenta externa. Especificamente, consiste de um agente preditor que se envolve em várias rodadas de reflexão, com seu código sendo verificado por um agente executor que executa o código contra casos de teste. Este fluxo de trabalho descoberto mostra que para codificação, uma estrutura que combina auto-correção iterativa com verificação externa é superior a designs MAS mais simples.

![][image4]

#### Fig. 4: (Cortesia dos Autores): O Framework Multi-Agent System Search (MASS) é um processo de otimização de três estágios que navega um espaço de busca abrangendo prompts otimizáveis (instruções e demonstrações) e blocos de construção de agentes configuráveis (Aggregate, Reflect, Debate, Summarize e Tool-use). O primeiro estágio, Otimização de Prompt Nível de Bloco, otimiza independentemente prompts para cada módulo de agente. Estágio dois, Otimização de Topologia de Fluxo de Trabalho, amostra configurações de sistema válidas de um espaço de design ponderado por influência, integrando os prompts otimizados. O estágio final, Otimização de Prompt Nível de Fluxo de Trabalho, envolve uma segunda rodada de otimização de prompt para todo o sistema multi-agente após a topologia de fluxo de trabalho ótima do Estágio dois ter sido identificada.

#### **3. Otimização de Prompt Nível de Fluxo de Trabalho:** O estágio final envolve uma otimização global dos prompts de todo o sistema. Após identificar a topologia de melhor desempenho, os prompts são fine-tuned como uma única entidade integrada para garantir que sejam adaptados para orquestração e que interdependências de agentes sejam otimizadas. Como exemplo, após encontrar a melhor topologia para o dataset DROP, o estágio de otimização final refina o prompt do agente "Preditor." O prompt final otimizado é altamente detalhado, começando fornecendo ao agente um resumo do próprio dataset, notando seu foco em "resposta a questões extrativas" e "informação numérica." Ele então inclui exemplos few-shot de comportamento correto de resposta a questões e enquadra a instrução central como um cenário de alto risco: "Você é uma IA altamente especializada encarregada de extrair informação numérica crítica para um relatório de notícias urgente. Uma transmissão ao vivo está dependendo de sua precisão e velocidade." Este prompt multi-facetado, combinando meta-conhecimento, exemplos e role-playing, é ajustado especificamente para o fluxo de trabalho final para maximizar precisão.

#### Descobertas e Princípios Chave: Experimentos demonstram que MAS otimizados por MASS superam significativamente sistemas manualmente projetados existentes e outros métodos de design automatizado através de uma gama de tarefas. Os princípios de design chave para MAS efetivos, como derivado desta pesquisa, são triplos:

* Otimizar agentes individuais com prompts de alta qualidade antes de compô-los.  
* Construir MAS compondo topologias influentes ao invés de explorar um espaço de busca não restrito.  
* Modelar e otimizar as interdependências entre agentes através de uma otimização conjunta final de nível de fluxo de trabalho.

Construindo sobre nossa discussão de técnicas de raciocínio chave, vamos primeiro examinar um princípio de desempenho central: a Lei de Escalamento de Inferência para LLMs. Esta lei declara que o desempenho de um modelo melhora previsivelmente conforme os recursos computacionais alocados a ele aumentam. Podemos ver este princípio em ação em sistemas complexos como Deep Research, onde um agente de IA aproveita estes recursos para investigar autonomamente um tópico dividindo-o em sub-questões, usando busca Web como ferramenta e sintetizando suas descobertas.

**Deep Research.** O termo "Deep Research" descreve uma categoria de ferramentas Agênticas de IA projetadas para agir como assistentes de pesquisa incansáveis e metódicos. Principais plataformas neste espaço incluem Perplexity AI, capacidades de pesquisa do Google Gemini e funções avançadas da OpenAI dentro do ChatGPT (veja Fig.5).

![][image5]Fig. 5: Google Deep Research para Coleta de Informação

Uma mudança fundamental introduzida por estas ferramentas é a mudança no processo de busca em si. Uma busca padrão fornece links imediatos, deixando o trabalho de síntese para você. Deep Research opera em um modelo diferente. Aqui, você encarrega uma IA com uma consulta complexa e concede a ela um "orçamento de tempo"—geralmente alguns minutos. Em retorno por esta paciência, você recebe um relatório detalhado.

Durante este tempo, a IA trabalha em seu nome de forma agêntica. Ela executa autonomamente uma série de passos sofisticados que seriam incrivelmente demorados para uma pessoa:

1. Exploração Inicial: Executa múltiplas buscas direcionadas baseadas em seu prompt inicial.  
2. Raciocínio e Refinamento: Lê e analisa a primeira onda de resultados, sintetiza as descobertas e identifica criticamente lacunas, contradições ou áreas que requerem mais detalhe.  
3. Investigação de Acompanhamento: Baseado em seu raciocínio interno, conduz novas buscas mais sutis para preencher aquelas lacunas e aprofundar seu entendimento.  
4. Síntese Final: Após várias rodadas desta busca e raciocínio iterativos, compila toda a informação validada em um único resumo estruturado e coeso.

Esta abordagem sistemática garante uma resposta abrangente e bem raciocinada, aprimorando significativamente a eficiência e profundidade da coleta de informação, facilitando assim tomada de decisão mais agêntica.

Lei de Escalamento de Inferência

A Lei de Escalamento de Inferência para LLMs é um princípio fundamental que estabelece uma relação previsível entre recursos computacionais alocados e desempenho do modelo. Esta lei declara que o desempenho de um modelo melhora de forma previsível conforme os recursos computacionais alocados a ele aumentam. Isto significa que dedicar mais tempo de processamento, passos de raciocínio ou iterações durante a inferência frequentemente resulta em respostas mais precisas, coerentes e robustas.

Esta lei é particularmente relevante para agentes autônomos, pois permite que eles aloquem recursos computacionais dinamicamente baseados na complexidade da tarefa. Para problemas simples, um agente pode usar recursos mínimos para uma resposta rápida. Para problemas complexos, o agente pode dedicar mais recursos computacionais para análise mais profunda e deliberação, resultando em ações mais confiáveis e precisas.

A implementação prática desta lei pode ser vista em várias técnicas de raciocínio discutidas neste capítulo. Por exemplo, Chain-of-Thought permite que agentes dediquem mais passos de raciocínio para problemas complexos. Tree-of-Thought permite exploração de múltiplos caminhos de raciocínio. ReAct permite iterações de pensamento-ação-observação. Todas estas técnicas efetivamente implementam a Lei de Escalamento de Inferência ao permitir que agentes aloquem mais recursos computacionais para tarefas mais complexas.

# Principais Conclusões

* Ao tornar seu raciocínio explícito, agentes podem formular planos transparentes e multi-passo, que é a capacidade fundamental para ação autônoma e confiança do usuário.  
* O framework ReAct fornece agentes com seu loop operacional central, capacitando-os a mover além de mero raciocínio e interagir com ferramentas externas para agir dinamicamente e se adaptar dentro de um ambiente.  
* A Lei de Escalamento de Inferência implica que o desempenho de um agente não é apenas sobre o tamanho de seu modelo subjacente, mas seu "tempo de pensamento" alocado, permitindo ações autônomas mais deliberadas e de maior qualidade.  
* Chain-of-Thought (CoT) serve como o monólogo interno de um agente, fornecendo uma maneira estruturada de formular um plano dividindo um objetivo complexo em uma sequência de ações gerenciáveis.  
* Tree-of-Thought e Auto-Correção dão aos agentes a capacidade crucial de deliberar, permitindo que avaliem múltiplas estratégias, façam backtrack de erros e melhorem seus próprios planos antes da execução.  
* Frameworks colaborativos como Chain of Debates (CoD) sinalizam a mudança de agentes solitários para sistemas multi-agente, onde equipes de agentes podem raciocinar juntos para lidar com problemas mais complexos e reduzir vieses individuais.  
* Aplicações como Deep Research demonstram como estas técnicas culminam em agentes que podem executar tarefas complexas e de longa duração, como investigação aprofundada, completamente autonomamente em nome do usuário.  
* Para construir equipes efetivas de agentes, frameworks como MASS automatizam a otimização de como agentes individuais são instruídos e como interagem, garantindo que todo o sistema multi-agente execute de forma ótima.  
* Ao integrar estas técnicas de raciocínio, construímos agentes que não são apenas automatizados mas verdadeiramente autônomos, capazes de ser confiados para planejar, agir e resolver problemas complexos sem supervisão direta.

# Conclusões

A IA moderna está evoluindo de ferramentas passivas para agentes autônomos, capazes de lidar com objetivos complexos através de raciocínio estruturado. Este comportamento agêntico começa com um monólogo interno, alimentado por técnicas como Chain-of-Thought (CoT), que permite que um agente formule um plano coerente antes de agir. Autonomia verdadeira requer deliberação, que agentes alcançam através de Auto-Correção e Tree-of-Thought (ToT), permitindo que avaliem múltiplas estratégias e melhorem independentemente seu próprio trabalho. O salto pivotal para sistemas totalmente agênticos vem do framework ReAct, que capacita um agente a mover além do pensamento e começar a agir usando ferramentas externas. Isto estabelece o loop agêntico central de pensamento, ação e observação, permitindo que o agente adapte dinamicamente sua estratégia baseada em feedback ambiental.

A capacidade de um agente para deliberação profunda é alimentada pela Lei de Escalamento de Inferência, onde mais "tempo de pensamento" computacional se traduz diretamente em ações autônomas mais robustas. A próxima fronteira é o sistema multi-agente, onde frameworks como Chain of Debates (CoD) criam sociedades de agentes colaborativos que raciocinam juntos para alcançar um objetivo comum. Isto não é teórico; aplicações agênticas como Deep Research já demonstram como agentes autônomos podem executar investigações complexas e multi-passo em nome do usuário. O objetivo geral é engenhar agentes autônomos confiáveis e transparentes que podem ser confiados para gerenciar e resolver problemas intrincados independentemente. Em última análise, ao combinar raciocínio explícito com o poder de agir, estas metodologias estão completando a transformação da IA em verdadeiros solucionadores de problemas agênticos.

# Referências

Pesquisa relevante inclui:

1. "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models" por Wei et al. (2022)  
2. "Tree of Thoughts: Deliberate Problem Solving with Large Language Models" por Yao et al. (2023)  
3. "Program-Aided Language Models" por Gao et al. (2023)  
4. "ReAct: Synergizing Reasoning and Acting in Language Models" por Yao et al. (2023)  
5. Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for LLM Problem-Solving, 2024  
6. Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies, [https://arxiv.org/abs/2502.02533](https://arxiv.org/abs/2502.02533)
